{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1e08ed5",
   "metadata": {},
   "source": [
    "# Grad-CAM Visualization for Sickle Cell Classification\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook demonstrates the use of Gradient-weighted Class Activation Mapping (Grad-CAM) to visualize which regions of the input images are most important for the model's predictions. Grad-CAM helps us understand and interpret the decision-making process of our deep learning model, which is crucial for building trust in medical diagnosis applications.\n",
    "\n",
    "## What is Grad-CAM?\n",
    "\n",
    "Grad-CAM is a technique that produces a heatmap showing the importance of different regions in the image for the model's prediction. It works by:\n",
    "\n",
    "1. Computing the gradient of the class score (before softmax) with respect to the feature maps of the last convolutional layer\n",
    "2. Pooling these gradients to get importance weights\n",
    "3. Computing a weighted combination of the feature maps\n",
    "4. Applying ReLU to show only features that have a positive influence on the class of interest\n",
    "\n",
    "## Why is this important for medical imaging?\n",
    "\n",
    "1. **Model Interpretability**: Understand what features the model is focusing on\n",
    "2. **Error Analysis**: Identify potential biases or incorrect focus areas\n",
    "3. **Clinical Validation**: Ensure the model is looking at biologically relevant features\n",
    "4. **Trust Building**: Help clinicians understand and trust the model's predictions\n",
    "\n",
    "## Implementation Overview\n",
    "\n",
    "1. **Model Setup**:\n",
    "   - Load the pre-trained ResNet50 model\n",
    "   - Create a model that maps the input image to the activations of the last convolutional layer and the output predictions\n",
    "\n",
    "2. **Grad-CAM Algorithm**:\n",
    "   - Forward pass an image through the network\n",
    "   - Compute gradients of the top predicted class score with respect to the feature maps\n",
    "   - Generate the heatmap by weighting the feature maps with the corresponding gradients\n",
    "   - Apply ReLU to the heatmap to consider only features that have a positive influence\n",
    "\n",
    "3. **Visualization**:\n",
    "   - Superimpose the heatmap on the original image\n",
    "   - Compare model's attention with clinical knowledge\n",
    "\n",
    "## Expected Outputs\n",
    "\n",
    "For each test image, we'll display:\n",
    "1. The original image\n",
    "2. The Grad-CAM heatmap\n",
    "3. The superimposed visualization\n",
    "4. The model's prediction and confidence\n",
    "\n",
    "## Key Considerations\n",
    "\n",
    "1. **Clinical Relevance**: The heatmaps should highlight clinically relevant features (e.g., cell morphology)\n",
    "2. **False Positives/Negatives**: Pay special attention to misclassified examples\n",
    "3. **Artifacts**: Check if the model is focusing on image artifacts rather than biological features\n",
    "\n",
    "## Next Steps After Visualization\n",
    "\n",
    "1. **Error Analysis**: Identify patterns in model mistakes\n",
    "2. **Model Improvement**: Use insights to improve data augmentation or model architecture\n",
    "3. **Quantitative Evaluation**: Consider quantitative metrics for model interpretability\n",
    "4. **Clinical Review**: Have domain experts review the heatmaps for biological plausibility\n",
    "\n",
    "## References\n",
    "\n",
    "1. Selvaraju, R. R., et al. \"Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization.\" *IEEE International Conference on Computer Vision (ICCV)*, 2017.\n",
    "2. Adebayo, J., et al. \"Sanity Checks for Saliency Maps.\" *NeurIPS*, 2018.\n",
    "3. Holzinger, A., et al. \"Causability and Explainability of AI in Medicine.\" *Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery*, 2019.\n",
    "\n",
    "## Usage\n",
    "\n",
    "Run each cell sequentially to:\n",
    "1. Load the model and setup Grad-CAM\n",
    "2. Process test images\n",
    "3. Generate and visualize the attention maps\n",
    "4. Interpret the results\n",
    "\n",
    "> **Note**: This visualization is for research/educational purposes and should not be used for clinical decision making without proper validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cecba49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fdef1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /Applications/Projects/Sickle Cell Classifer/models/resnet50_model.h5\n",
      "Model file not found. Please check the path.\n",
      "Available files in models directory: ['resnet50_final.h5', 'resnet50_best.h5']\n",
      "Loading class indices from: /Applications/Projects/Sickle Cell Classifer/reports/class_indices.json\n",
      "Loaded class mapping: {0: 'Negative', 1: 'Positive'}\n",
      "\n",
      "Failed to load the model. Please check if the model file exists and is accessible.\n",
      "You may need to train the model first by running the training notebook.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import json\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Load the model\n",
    "def load_trained_model():\n",
    "    try:\n",
    "        # Try to load the model\n",
    "        model_path = os.path.join('..', '..', 'models', 'resnet50_model.h5')\n",
    "        print(f\"Loading model from: {os.path.abspath(model_path)}\")\n",
    "        \n",
    "        if not os.path.exists(model_path):\n",
    "            print(\"Model file not found. Please check the path.\")\n",
    "            # Try to find any .h5 files in the models directory\n",
    "            models_dir = os.path.join('..', '..', 'models')\n",
    "            if os.path.exists(models_dir):\n",
    "                print(f\"Available files in models directory: {os.listdir(models_dir)}\")\n",
    "            return None\n",
    "        \n",
    "        # Load the model\n",
    "        model = load_model(model_path)\n",
    "        print(\"Model loaded successfully!\")\n",
    "        print(f\"Model input shape: {model.input_shape}\")\n",
    "        print(f\"Model output shape: {model.output_shape}\")\n",
    "        return model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Load class indices\n",
    "def load_class_indices():\n",
    "    try:\n",
    "        class_indices_path = os.path.join('..', '..', 'reports', 'class_indices.json')\n",
    "        print(f\"Loading class indices from: {os.path.abspath(class_indices_path)}\")\n",
    "        \n",
    "        if not os.path.exists(class_indices_path):\n",
    "            print(\"Class indices file not found. Using default class mapping.\")\n",
    "            return {'0': 'Negative', '1': 'Positive'}\n",
    "            \n",
    "        with open(class_indices_path, 'r') as f:\n",
    "            class_indices = json.load(f)\n",
    "        \n",
    "        # Create reverse mapping (index to class name)\n",
    "        idx_to_class = {int(v): k for k, v in class_indices.items()}\n",
    "        print(f\"Loaded class mapping: {idx_to_class}\")\n",
    "        return idx_to_class\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading class indices: {str(e)}\")\n",
    "        return {0: 'Negative', 1: 'Positive'}  # Default fallback\n",
    "\n",
    "# Load the model and class indices\n",
    "model = load_trained_model()\n",
    "idx_to_class = load_class_indices()\n",
    "\n",
    "if model is None:\n",
    "    print(\"\\nFailed to load the model. Please check if the model file exists and is accessible.\")\n",
    "    print(\"You may need to train the model first by running the training notebook.\")\n",
    "else:\n",
    "    print(\"\\nModel and class indices loaded successfully!\")\n",
    "    print(f\"Available classes: {idx_to_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6982c5c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = '../../models/resnet50_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load the saved model\u001b[39;00m\n\u001b[32m      2\u001b[39m model_path = os.path.join(\u001b[33m'\u001b[39m\u001b[33m..\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m..\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmodels\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mresnet50_model.h5\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m model = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Load class indices\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os.path.join(\u001b[33m'\u001b[39m\u001b[33m..\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m..\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mreports\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mclass_indices.json\u001b[39m\u001b[33m'\u001b[39m), \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/Projects/Sickle Cell Classifer/.venv/lib/python3.11/site-packages/keras/src/saving/saving_api.py:196\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(filepath, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    189\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib.load_model(\n\u001b[32m    190\u001b[39m         filepath,\n\u001b[32m    191\u001b[39m         custom_objects=custom_objects,\n\u001b[32m    192\u001b[39m         \u001b[38;5;28mcompile\u001b[39m=\u001b[38;5;28mcompile\u001b[39m,\n\u001b[32m    193\u001b[39m         safe_mode=safe_mode,\n\u001b[32m    194\u001b[39m     )\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath).endswith((\u001b[33m\"\u001b[39m\u001b[33m.h5\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m.hdf5\u001b[39m\u001b[33m\"\u001b[39m)):\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_h5_format\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model_from_hdf5\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath).endswith(\u001b[33m\"\u001b[39m\u001b[33m.keras\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    201\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    202\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    203\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mzip file.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    204\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/Projects/Sickle Cell Classifer/.venv/lib/python3.11/site-packages/keras/src/legacy/saving/legacy_h5_format.py:115\u001b[39m, in \u001b[36mload_model_from_hdf5\u001b[39m\u001b[34m(filepath, custom_objects, compile)\u001b[39m\n\u001b[32m    113\u001b[39m opened_new_file = \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath, h5py.File)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m opened_new_file:\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     f = \u001b[43mh5py\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    117\u001b[39m     f = filepath\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/Projects/Sickle Cell Classifer/.venv/lib/python3.11/site-packages/h5py/_hl/files.py:564\u001b[39m, in \u001b[36mFile.__init__\u001b[39m\u001b[34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[39m\n\u001b[32m    555\u001b[39m     fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[32m    556\u001b[39m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[32m    557\u001b[39m                      alignment_threshold=alignment_threshold,\n\u001b[32m    558\u001b[39m                      alignment_interval=alignment_interval,\n\u001b[32m    559\u001b[39m                      meta_block_size=meta_block_size,\n\u001b[32m    560\u001b[39m                      **kwds)\n\u001b[32m    561\u001b[39m     fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,\n\u001b[32m    562\u001b[39m                      fs_persist=fs_persist, fs_threshold=fs_threshold,\n\u001b[32m    563\u001b[39m                      fs_page_size=fs_page_size)\n\u001b[32m--> \u001b[39m\u001b[32m564\u001b[39m     fid = \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    567\u001b[39m     \u001b[38;5;28mself\u001b[39m._libver = libver\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/Projects/Sickle Cell Classifer/.venv/lib/python3.11/site-packages/h5py/_hl/files.py:238\u001b[39m, in \u001b[36mmake_fid\u001b[39m\u001b[34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[39m\n\u001b[32m    236\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[32m    237\u001b[39m         flags |= h5f.ACC_SWMR_READ\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m     fid = \u001b[43mh5f\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m mode == \u001b[33m'\u001b[39m\u001b[33mr+\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    240\u001b[39m     fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:56\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:57\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/h5f.pyx:102\u001b[39m, in \u001b[36mh5py.h5f.open\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] Unable to synchronously open file (unable to open file: name = '../../models/resnet50_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "model_path = os.path.join('..', '..', 'models', 'resnet50_model.h5')\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# Load class indices\n",
    "with open(os.path.join('..', '..', 'reports', 'class_indices.json'), 'r') as f:\n",
    "    class_indices = json.load(f)\n",
    "    \n",
    "# Reverse the class indices for lookup\n",
    "idx_to_class = {v: k for k, v in class_indices.items()}\n",
    "\n",
    "# Print class mapping for reference\n",
    "print(\"Class mapping:\", idx_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2e29cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    # Create a model that maps the input image to the activations of the last conv layer\n",
    "    grad_model = Model(\n",
    "        inputs=model.inputs,\n",
    "        outputs=[model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    # Compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(predictions[0])\n",
    "        class_channel = predictions[:, pred_index]\n",
    "\n",
    "    # This is the gradient of the output neuron (top predicted or chosen)\n",
    "    # with regard to the output feature map of the last conv layer\n",
    "    grads = tape.gradient(class_channel, conv_outputs)\n",
    "\n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    # then sum all the channels to obtain the heatmap class activation\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa476d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(img_path, target_size=(224, 224)):\n",
    "    # Load and preprocess the image\n",
    "    img = image.load_img(img_path, target_size=target_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    return img_array, img\n",
    "\n",
    "def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n",
    "    # Load the original image\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Resize heatmap to be the same size as the original image\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "    \n",
    "    # Convert heatmap to RGB\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    \n",
    "    # Superimpose the heatmap on the original image\n",
    "    superimposed_img = heatmap * alpha + img\n",
    "    superimposed_img = np.clip(superimposed_img, 0, 255).astype('uint8')\n",
    "    \n",
    "    # Display the result\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n",
    "    \n",
    "    ax[0].imshow(img)\n",
    "    ax[0].set_title('Original Image')\n",
    "    ax[0].axis('off')\n",
    "    \n",
    "    ax[1].imshow(heatmap)\n",
    "    ax[1].set_title('GradCAM Heatmap')\n",
    "    ax[1].axis('off')\n",
    "    \n",
    "    ax[2].imshow(superimposed_img)\n",
    "    ax[2].set_title('Superimposed')\n",
    "    ax[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(cam_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e7ba98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gradcam(image_path, model, last_conv_layer_name='conv5_block3_out'):\n",
    "    # Preprocess the image\n",
    "    img_array, original_img = load_and_preprocess_image(image_path)\n",
    "    \n",
    "    # Make prediction\n",
    "    preds = model.predict(img_array)\n",
    "    pred_class = np.argmax(preds[0])\n",
    "    confidence = np.max(preds[0])\n",
    "    \n",
    "    print(f\"Predicted class: {idx_to_class[pred_class]} (confidence: {confidence:.2f})\")\n",
    "    \n",
    "    # Generate class activation heatmap\n",
    "    heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
    "    \n",
    "    # Save and display the GradCAM output\n",
    "    save_and_display_gradcam(image_path, heatmap)\n",
    "    \n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76c513a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for test images in: /Applications/Projects/Sickle Cell Classifer/Data\n",
      "Found 2 classes: Positive, Negative\n",
      "\n",
      "No images found in class directory: Positive\n",
      "\n",
      "No images found in class directory: Negative\n",
      "\n",
      "GradCAM visualization complete!\n"
     ]
    }
   ],
   "source": [
    "# Example usage with a test image\n",
    "test_image_dir = os.path.join('..', '..', 'Data')  # Updated path to point to the Data directory\n",
    "\n",
    "# Check if test directory exists\n",
    "if not os.path.exists(test_image_dir):\n",
    "    raise FileNotFoundError(f\"Data directory not found at: {os.path.abspath(test_image_dir)}\")\n",
    "\n",
    "print(f\"Looking for test images in: {os.path.abspath(test_image_dir)}\")\n",
    "\n",
    "# Get all class directories (Positive and Negative)\n",
    "class_dirs = [d for d in os.listdir(test_image_dir) \n",
    "             if os.path.isdir(os.path.join(test_image_dir, d)) and \n",
    "             d in ['Positive', 'Negative']]  # Only include these specific directories\n",
    "\n",
    "if not class_dirs:\n",
    "    print(\"No class directories found in the data directory.\")\n",
    "else:\n",
    "    print(f\"Found {len(class_dirs)} classes: {', '.join(class_dirs)}\")\n",
    "\n",
    "# Process one image from each class\n",
    "for class_dir in class_dirs:\n",
    "    class_path = os.path.join(test_image_dir, class_dir)\n",
    "    try:\n",
    "        # Get all image files in the class directory\n",
    "        image_files = [\n",
    "            f for f in os.listdir(class_path) \n",
    "            if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))\n",
    "        ]\n",
    "        \n",
    "        if not image_files:\n",
    "            print(f\"\\nNo images found in class directory: {class_dir}\")\n",
    "            continue\n",
    "            \n",
    "        # Take the first image\n",
    "        test_image_path = os.path.join(class_path, image_files[0])\n",
    "        \n",
    "        # Verify the image exists and is readable\n",
    "        if not os.path.exists(test_image_path):\n",
    "            print(f\"\\nImage not found: {test_image_path}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Analyzing image from class: {class_dir}\")\n",
    "        print(f\"Image: {image_files[0]}\")\n",
    "        print(f\"Full path: {os.path.abspath(test_image_path)}\")\n",
    "        \n",
    "        # Run GradCAM visualization\n",
    "        try:\n",
    "            _ = run_gradcam(test_image_path, model)\n",
    "            print(f\"Successfully processed: {image_files[0]}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_files[0]}: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing class {class_dir}: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        continue\n",
    "\n",
    "print(\"\\nGradCAM visualization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b6fcfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for images in: /Applications/Projects/Sickle Cell Classifer/Data\n",
      "\n",
      "==================================================\n",
      "Analyzing image from class: Positive\n",
      "Image: 63.jpg\n",
      "Full path: /Applications/Projects/Sickle Cell Classifer/Data/Positive/Unlabelled/63.jpg\n",
      "Error processing 63.jpg: name 'model' is not defined\n",
      "\n",
      "Class directory not found: ../../Data/Negative/Unlabelled\n",
      "\n",
      "GradCAM visualization complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/xz/1mhz2xvx29xdpqhg3kk69fph0000gn/T/ipykernel_50202/1083704799.py\", line 41, in <module>\n",
      "    _ = run_gradcam(test_image_path, model)\n",
      "                                     ^^^^^\n",
      "NameError: name 'model' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Example usage with a test image\n",
    "data_dir = os.path.join('..', '..', 'Data')  # Base data directory\n",
    "class_dirs = ['Positive', 'Negative']  # Expected class directories\n",
    "\n",
    "print(f\"Looking for images in: {os.path.abspath(data_dir)}\")\n",
    "\n",
    "# Process one image from each class\n",
    "for class_dir in class_dirs:\n",
    "    class_path = os.path.join(data_dir, class_dir, 'Unlabelled')  # Added 'Unlabelled' subdirectory\n",
    "    \n",
    "    if not os.path.exists(class_path):\n",
    "        print(f\"\\nClass directory not found: {class_path}\")\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        # Get all image files in the Unlabelled subdirectory\n",
    "        image_files = [\n",
    "            f for f in os.listdir(class_path) \n",
    "            if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))\n",
    "        ]\n",
    "        \n",
    "        if not image_files:\n",
    "            print(f\"\\nNo images found in: {class_path}\")\n",
    "            continue\n",
    "            \n",
    "        # Take the first image\n",
    "        test_image_path = os.path.join(class_path, image_files[0])\n",
    "        \n",
    "        # Verify the image exists and is readable\n",
    "        if not os.path.exists(test_image_path):\n",
    "            print(f\"\\nImage not found: {test_image_path}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Analyzing image from class: {class_dir}\")\n",
    "        print(f\"Image: {image_files[0]}\")\n",
    "        print(f\"Full path: {os.path.abspath(test_image_path)}\")\n",
    "        \n",
    "        # Run GradCAM visualization\n",
    "        try:\n",
    "            _ = run_gradcam(test_image_path, model)\n",
    "            print(f\"Successfully processed: {image_files[0]}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_files[0]}: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing class {class_dir}: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        continue\n",
    "\n",
    "print(\"\\nGradCAM visualization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30c9039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying model...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# First, verify the model is loaded correctly\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mVerifying model...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mmodel\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mError: Model is not loaded!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# First, verify the model is loaded correctly\n",
    "print(\"Verifying model...\")\n",
    "if model is None:\n",
    "    print(\"Error: Model is not loaded!\")\n",
    "else:\n",
    "    print(\"Model loaded successfully\")\n",
    "    print(f\"Model input shape: {model.input_shape}\")\n",
    "    print(f\"Model output shape: {model.output_shape}\")\n",
    "\n",
    "# Example usage with a test image\n",
    "data_dir = os.path.abspath(os.path.join('..', '..', 'Data'))  # Get absolute path\n",
    "class_dirs = ['Positive', 'Negative']  # Expected class directories\n",
    "\n",
    "print(f\"\\nLooking for images in: {data_dir}\")\n",
    "\n",
    "# Process one image from each class\n",
    "for class_dir in class_dirs:\n",
    "    class_path = os.path.join(data_dir, class_dir, 'Unlabelled')\n",
    "    print(f\"\\nChecking directory: {class_path}\")\n",
    "    \n",
    "    if not os.path.exists(class_path):\n",
    "        print(f\"Directory does not exist: {class_path}\")\n",
    "        # List contents of parent directory to help debug\n",
    "        parent_dir = os.path.dirname(class_path)\n",
    "        if os.path.exists(parent_dir):\n",
    "            print(f\"Contents of {parent_dir}: {os.listdir(parent_dir)}\")\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        # List all files in the directory\n",
    "        all_files = os.listdir(class_path)\n",
    "        print(f\"Found {len(all_files)} items in directory\")\n",
    "        \n",
    "        # Filter for image files\n",
    "        image_files = [\n",
    "            f for f in all_files \n",
    "            if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))\n",
    "        ]\n",
    "        \n",
    "        print(f\"Found {len(image_files)} image files\")\n",
    "        \n",
    "        if not image_files:\n",
    "            print(f\"No image files found in: {class_path}\")\n",
    "            print(f\"File types present: {set(os.path.splitext(f)[1] for f in all_files)}\")\n",
    "            continue\n",
    "            \n",
    "        # Take the first image\n",
    "        test_image_path = os.path.join(class_path, image_files[0])\n",
    "        print(f\"Selected image: {test_image_path}\")\n",
    "        \n",
    "        # Verify the image exists and is readable\n",
    "        if not os.path.exists(test_image_path):\n",
    "            print(f\"Image file not found: {test_image_path}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Analyzing image from class: {class_dir}\")\n",
    "        print(f\"Image: {image_files[0]}\")\n",
    "        print(f\"Full path: {test_image_path}\")\n",
    "        \n",
    "        # Run GradCAM visualization\n",
    "        try:\n",
    "            print(\"Running GradCAM...\")\n",
    "            _ = run_gradcam(test_image_path, model)\n",
    "            print(f\"Successfully processed: {image_files[0]}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_files[0]}: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing class {class_dir}: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        continue\n",
    "\n",
    "print(\"\\nGradCAM visualization complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_clean",
   "language": "python",
   "name": "tf_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
